{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXu08MAes57m","executionInfo":{"status":"ok","timestamp":1765374944272,"user_tz":360,"elapsed":7686,"user":{"displayName":"Advait Tilak","userId":"04081556924397245104"}},"outputId":"5ad35e6b-bf94-4b5d-f9bf-410fe6628f7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q -U segmentation-models-pytorch albumentations monai"]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import segmentation_models_pytorch as smp\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from PIL import Image\n","from tqdm import tqdm\n","import random\n","\n","from monai.losses import DiceLoss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3W5kK12rtEYl","executionInfo":{"status":"ok","timestamp":1765375078733,"user_tz":360,"elapsed":28736,"user":{"displayName":"Advait Tilak","userId":"04081556924397245104"}},"outputId":"f646fc76-153b-4b44-cafa-67cd33f65bee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n"]}]},{"cell_type":"code","source":["class Config:\n","    # -- Base Paths --\n","    BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/phenocyte_seg/phenocyte_seg/\"\n","\n","    # Path to ORIGINAL images (JPGs) and GT masks\n","    IMAGE_DIR = os.path.join(BASE_PATH, \"images\")\n","\n","    MASK_DIR = os.path.join(BASE_PATH,\"masks\")\n","\n","    # Path to DISTANCE WEIGHT MAPS\n","    DIST_WEIGHT_DIR = os.path.join(BASE_PATH,\"augmented masks v3/distance_weights\")\n","\n","    # Data QC Report & Splits\n","    QC_REPORT_CSV = os.path.join(BASE_PATH, \"missing_classes_from_mask.csv\")\n","    SPLIT_CSV = os.path.join(BASE_PATH, \"dataset_split.csv\")\n","\n","    # -- Output --\n","    OUTPUT_DIR = os.path.join(BASE_PATH, \"outputs_v6_final\")\n","    OUTPUT_MASK_DIR = os.path.join(OUTPUT_DIR, \"pred_masks\")\n","    COLOR_MASK_DIR = os.path.join(OUTPUT_DIR, \"color_masks\")\n","\n","    # -- Model Hyperparameters --\n","    ARCHITECTURE = 'unetplusplus'\n","    ENCODER = 'resnet34'\n","    ENCODER_WEIGHTS = 'imagenet'\n","    LEARNING_RATE = 1e-4\n","    OPTIMIZER = 'AdamW'\n","\n","    # -- Training Settings --\n","    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    BATCH_SIZE = 4\n","    NUM_EPOCHS = 40\n","\n","    IMAGE_HEIGHT = 512\n","    IMAGE_WIDTH = 512\n","\n","    NUM_CLASSES = 5\n","\n","    # -- LOSS CONFIGURATION --\n","    # Weights for 5 classes: [Bg, Stem, Leaf, Root, Seed]\n","    CLASS_WEIGHTS = torch.tensor([\n","        1.0,  # Background\n","        9.0,  # Stem\n","        7.0,  # Leaf\n","        9.0,  # Root\n","        10.0  # Seed\n","    ], device=DEVICE)\n","\n","    # Boundary Importance Scale\n","    BOUNDARY_SCALE = 2.0\n","\n","    # -- Visualization --\n","    COLOR_MAP = {\n","        0: (0, 0, 0),        # background\n","        1: (139, 69, 19),    # stem - brown\n","        2: (0, 255, 0),      # leaf - green\n","        3: (255, 255, 0),    # root - yellow\n","        4: (255, 0, 0),      # seed - red\n","    }\n","\n","os.makedirs(Config.OUTPUT_MASK_DIR, exist_ok=True)\n","os.makedirs(Config.COLOR_MASK_DIR, exist_ok=True)\n"],"metadata":{"id":"6gMPIjsFtGTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_splits_v6_original(image_dir, mask_dir, dist_dir, split_csv_path, qc_csv_path):\n","    print(\"--- Configuring V6 Splits (Original Masks + Distance) ---\")\n","\n","    # Load mislabeled\n","    excluded_masks = set()\n","    if os.path.exists(qc_csv_path):\n","        df_qc = pd.read_csv(qc_csv_path)\n","        bad_rows = df_qc[df_qc['Mask_correct'].astype(str).str.upper() == 'FALSE']\n","        excluded_masks = set(bad_rows['filename'].tolist())\n","\n","    # Load Split Map\n","    if not os.path.exists(split_csv_path): raise FileNotFoundError(\"Split CSV missing\")\n","    try: df_split = pd.read_csv(split_csv_path)\n","    except: df_split = pd.read_excel(split_csv_path.replace('.csv', '.xlsx'))\n","\n","    train_files, val_files, test_files = [], [], []\n","\n","    for idx, row in df_split.iterrows():\n","        img_name = row['img_name']\n","        set_type = row['set'].lower().strip()\n","\n","        # Verify Image\n","        if not os.path.exists(os.path.join(image_dir, img_name)): continue\n","\n","        base_name = os.path.splitext(img_name)[0]\n","\n","        # Verify PNG Mask (V4 Style)\n","        mask_name = base_name + \"_mask.png\"\n","        if not os.path.exists(os.path.join(mask_dir, mask_name)): continue\n","\n","        # Verify Distance Map (TSV/CSV) - STRICT for V6\n","        dist_path = None\n","        for name in [base_name + \".csv\", base_name + \"_weights.csv\", base_name + \".tsv\"]:\n","            if os.path.exists(os.path.join(dist_dir, name)): dist_path = name; break\n","        if not dist_path: continue\n","\n","        # QC Check\n","        if mask_name in excluded_masks: continue\n","\n","        if set_type == 'train': train_files.append(img_name)\n","        elif set_type == 'val': val_files.append(img_name)\n","        elif set_type == 'test': test_files.append(img_name)\n","\n","    print(f\"Train: {len(train_files)} | Val: {len(val_files)} | Test: {len(test_files)}\")\n","    return train_files, val_files, test_files\n"],"metadata":{"id":"VBZDZFcjtKgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BoundaryDiceDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, dist_dir, image_filenames, transform=None):\n","        self.image_dir = image_dir; self.mask_dir = mask_dir; self.dist_dir = dist_dir\n","        self.transform = transform; self.images = image_filenames\n","\n","    def __len__(self): return len(self.images)\n","\n","    def _load_csv(self, path):\n","        if path is None: return None\n","        try:\n","            try: df = pd.read_csv(path, header=None, sep=',' if path.endswith('.csv') else '\\t')\n","            except: df = pd.read_csv(path, header=None, delim_whitespace=True)\n","            return df.values.astype(np.float32)\n","        except: return None\n","\n","    def __getitem__(self, index):\n","        img_name = self.images[index]\n","        base_name = os.path.splitext(img_name)[0]\n","\n","        # 1. Load Image\n","        img_path = os.path.join(self.image_dir, img_name)\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","\n","        # 2. Load Mask (PNG - Original V4 Style)\n","        mask_name = base_name + \"_mask.png\"\n","        mask_path = os.path.join(self.mask_dir, mask_name)\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n","\n","        # 3. Load Distance Map (TSV)\n","        dist_path = None\n","        for name in [base_name + \".csv\", base_name + \"_weights.csv\", base_name + \".tsv\"]:\n","            p = os.path.join(self.dist_dir, name)\n","            if os.path.exists(p): dist_path = p; break\n","\n","        dist_map = self._load_csv(dist_path)\n","\n","        if dist_map is None: dist_map = np.zeros_like(mask)\n","\n","        # Smart Padding / Sizing\n","\n","        h_img, w_img = image.shape[:2]\n","        h_dist, w_dist = dist_map.shape[:2]\n","\n","        if (h_img != h_dist) or (w_img != w_dist):\n","\n","            cropped_dist = dist_map[:h_img, :w_img]\n","            # Handle case where image > dist map\n","            if cropped_dist.shape != (h_img, w_img):\n","                temp = np.zeros((h_img, w_img), dtype=np.float32)\n","                h_c, w_c = cropped_dist.shape\n","                temp[:h_c, :w_c] = cropped_dist\n","                cropped_dist = temp\n","\n","            dist_map = cropped_dist\n","\n","        original_size = (h_img, w_img)\n","\n","        # 5. Augmentations\n","        if self.transform:\n","            aug = self.transform(image=image, mask=mask, dist_map=dist_map)\n","            image = aug['image']; mask = aug['mask']; dist_map = aug['dist_map']\n","\n","        # Clip mask to 5 classes\n","        mask[mask >= Config.NUM_CLASSES] = 0\n","\n","        return image, mask.long(), dist_map.float(), original_size"],"metadata":{"id":"kaVCMfrZtSyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_transform = A.Compose([\n","    A.Resize(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH),\n","    A.Rotate(limit=35, p=0.5), A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5),\n","    A.Normalize(mean=[0.0,0.0,0.0], std=[1.0,1.0,1.0], max_pixel_value=255.0),\n","    ToTensorV2(),\n","], additional_targets={'dist_map': 'mask'})\n","\n","val_transform = A.Compose([\n","    A.Resize(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH),\n","    A.Normalize(mean=[0.0,0.0,0.0], std=[1.0,1.0,1.0], max_pixel_value=255.0),\n","    ToTensorV2(),\n","], additional_targets={'dist_map': 'mask'})\n"],"metadata":{"id":"jgD4qBMAtZXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BoundaryWeightedDiceLoss(nn.Module):\n","    def __init__(self, class_weights, boundary_scale=2.0, smooth=1e-5):\n","        super().__init__()\n","        self.class_weights = class_weights\n","        self.boundary_scale = boundary_scale\n","        self.smooth = smooth\n","\n","    def forward(self, preds, targets, dist_maps):\n","        \"\"\"\n","        Calculates Dice Loss but weights pixels near boundaries more heavily.\n","        \"\"\"\n","        # Apply Softmax to get probabilities (B, C, H, W)\n","        probs = torch.softmax(preds, dim=1)\n","\n","        # One-Hot Encode Targets (B, C, H, W)\n","        targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=Config.NUM_CLASSES).permute(0, 3, 1, 2).float()\n","\n","        # Create Boundary Weight Map (B, 1, H, W)\n","        # 1.0 (Center) -> 1.0 + Scale (Boundary)\n","        # Unsqueeze dist_map to match channel dim for broadcasting\n","        spatial_weights = 1.0 + (self.boundary_scale * dist_maps.unsqueeze(1))\n","\n","        # Calculate Weighted Intersection & Union\n","        numerator = 2.0 * (probs * targets_one_hot * spatial_weights).sum(dim=(2, 3))\n","        denominator = ((probs + targets_one_hot) * spatial_weights).sum(dim=(2, 3))\n","\n","        # Calculate Dice per class per batch\n","        dice_score = (numerator + self.smooth) / (denominator + self.smooth)\n","        # Calculate loss per class (1 - Dice)\n","        dice_loss = 1.0 - dice_score\n","\n","        # Apply weights to the LOSS, not the Dice score\n","        weighted_loss = dice_loss * self.class_weights\n","\n","        # Return the mean loss\n","        return weighted_loss.mean()\n","\n","def mask_to_rgb(mask_tensor, color_map):\n","    if torch.is_tensor(mask_tensor): mask = mask_tensor.cpu().numpy().squeeze()\n","    else: mask = mask_tensor.squeeze()\n","    rgb = np.zeros((*mask.shape, 3), dtype=np.uint8)\n","    for k, v in color_map.items(): rgb[mask==k] = v\n","    return rgb\n","\n","def save_predictions_fn(loader, model, folder_basename=\"\"):\n","    print(f\"\\n--- Saving predictions for {folder_basename} set ---\")\n","    model.eval()\n","    os.makedirs(os.path.join(Config.OUTPUT_MASK_DIR, folder_basename), exist_ok=True)\n","    os.makedirs(os.path.join(Config.COLOR_MASK_DIR, folder_basename), exist_ok=True)\n","\n","    for idx in tqdm(range(len(loader.dataset))):\n","        img_tensor, _, _, (original_h, original_w) = loader.dataset[idx]\n","        with torch.no_grad():\n","            img_tensor = img_tensor.to(Config.DEVICE).unsqueeze(0)\n","            preds = model(img_tensor)\n","            final_mask = torch.argmax(preds, dim=1).squeeze(0)\n","\n","        pred_np = final_mask.cpu().numpy().astype(np.uint8)\n","        resized = cv2.resize(pred_np, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n","\n","        fname = loader.dataset.images[idx]\n","        name = os.path.splitext(fname)[0]\n","\n","        Image.fromarray(resized).save(os.path.join(Config.OUTPUT_MASK_DIR, folder_basename, name + \"_mask.png\"))\n","        rgb = mask_to_rgb(resized, Config.COLOR_MAP)\n","        Image.fromarray(rgb).save(os.path.join(Config.COLOR_MASK_DIR, folder_basename, name + \"_mask.png\"))\n","    model.train()\n","\n","def train_fn(loader, model, optimizer, loss_fn, scaler):\n","    loop = tqdm(loader, desc=\"Training\")\n","    total_loss = 0\n","    for batch_idx, (data, targets, dist, _) in enumerate(loop):\n","        data, targets, dist = data.to(Config.DEVICE), targets.to(Config.DEVICE), dist.to(Config.DEVICE)\n","\n","        with torch.amp.autocast('cuda'):\n","            out = model(data)\n","            loss = loss_fn(out, targets, dist)\n","\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        total_loss += loss.item()\n","        loop.set_postfix(loss=loss.item())\n","    return total_loss / len(loader)\n","\n","def eval_fn(loader, model, loss_fn):\n","    model.eval()\n","    total_loss = 0\n","    loop = tqdm(loader, desc=\"Validation\")\n","    with torch.no_grad():\n","        for data, targets, dist, _ in loop:\n","            data, targets, dist = data.to(Config.DEVICE), targets.to(Config.DEVICE), dist.to(Config.DEVICE)\n","            loss = loss_fn(model(data), targets, dist)\n","            total_loss += loss.item()\n","            loop.set_postfix(val_loss=loss.item())\n","    model.train()\n","    return total_loss / len(loader)\n"],"metadata":{"id":"Gno4_GeBtss6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    print(f\"Using device: {Config.DEVICE}\")\n","    train_files, val_files, test_files = get_splits_v6_original(\n","        Config.IMAGE_DIR, Config.MASK_DIR, Config.DIST_WEIGHT_DIR,\n","        Config.SPLIT_CSV, Config.QC_REPORT_CSV\n","    )\n","\n","    if not train_files:\n","        print(\"Error: No matching data found!\")\n","        return\n","\n","    train_ds = BoundaryDiceDataset(Config.IMAGE_DIR, Config.MASK_DIR, Config.DIST_WEIGHT_DIR, train_files, train_transform)\n","    val_ds = BoundaryDiceDataset(Config.IMAGE_DIR, Config.MASK_DIR, Config.DIST_WEIGHT_DIR, val_files, val_transform)\n","    test_ds = BoundaryDiceDataset(Config.IMAGE_DIR, Config.MASK_DIR, Config.DIST_WEIGHT_DIR, test_files, val_transform)\n","\n","    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False)\n","    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n","\n","    model = smp.create_model(\n","        arch=Config.ARCHITECTURE, encoder_name=Config.ENCODER,\n","        encoder_weights=Config.ENCODER_WEIGHTS, in_channels=3, classes=Config.NUM_CLASSES\n","    ).to(Config.DEVICE)\n","\n","    loss_fn = BoundaryWeightedDiceLoss(class_weights=Config.CLASS_WEIGHTS, boundary_scale=Config.BOUNDARY_SCALE)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n","    scaler = torch.amp.GradScaler('cuda')\n","    best_val = float('inf')\n","\n","    for epoch in range(Config.NUM_EPOCHS):\n","        print(f\"\\n--- Epoch {epoch+1}/{Config.NUM_EPOCHS} ---\")\n","        avg_train = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","        avg_val = eval_fn(val_loader, model, loss_fn)\n","        print(f\"Train: {avg_train:.4f} | Val: {avg_val:.4f}\")\n","        if avg_val < best_val:\n","            best_val = avg_val\n","            torch.save(model.state_dict(), os.path.join(Config.BASE_PATH, \"best_model_v6_boundary.pth\"))\n","            print(\"=> Saved new best model\")\n","\n","    print(\"\\n--- Testing ---\")\n","    model.load_state_dict(torch.load(os.path.join(Config.BASE_PATH, \"best_model_v6_boundary.pth\")))\n","    save_predictions_fn(test_loader, model, folder_basename=\"test_set\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"hQEQ5etgtsfg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Performance Evaluation"],"metadata":{"id":"XFuA_xlUn34n"}},{"cell_type":"code","source":["!pip install -q monai pandas\n","\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import torch\n","from tqdm import tqdm\n","from monai.metrics import (\n","    compute_dice,\n","    compute_iou,\n","    compute_hausdorff_distance\n",")\n","\n","# Ground Truth Masks\n","GT_MASK_DIR = \"/content/drive/MyDrive/Colab Notebooks/phenocyte_seg/phenocyte_seg/masks/\"\n","\n","# Predicted Masks (From V4 Output)\n","PRED_MASK_DIR = \"/content/drive/MyDrive/Colab Notebooks/phenocyte_seg/phenocyte_seg/outputs_v6_final/pred_masks/test_set/\"\n","\n","# --- CLASS MAP ---\n","NUM_CLASSES = 5\n","CLASS_MAP = {\n","    0: \"Background\",\n","    1: \"Stem\",\n","    2: \"Leaf\",\n","    3: \"Root\",\n","    4: \"Seed\",\n","}\n","\n","def to_one_hot(mask, num_classes):\n","    mask[mask >= num_classes] = 0\n","\n","    one_hot = np.eye(num_classes)[mask]\n","    one_hot = np.transpose(one_hot, (2, 0, 1))\n","    return torch.from_numpy(one_hot).unsqueeze(0)\n","\n","def run_analysis():\n","    print(\"Starting V4 opt Analysis...\")\n","    print(f\"GT Directory: {GT_MASK_DIR}\")\n","    print(f\"Pred Directory: {PRED_MASK_DIR}\")\n","\n","    results_list = []\n","    pred_files = [f for f in os.listdir(PRED_MASK_DIR) if f.endswith('.png')]\n","\n","    if len(pred_files) == 0:\n","        print(\"Error: No prediction files found! Check your PRED_MASK_DIR path.\")\n","        return\n","\n","    for filename in tqdm(pred_files):\n","        pred_path = os.path.join(PRED_MASK_DIR, filename)\n","        gt_path = os.path.join(GT_MASK_DIR, filename.replace(\".png\", \"_mask.png\"))\n","\n","        if not os.path.exists(gt_path):\n","            print(f\"Skipping {filename}: GT mask not found.\")\n","            continue\n","\n","        # Load Masks\n","        gt_mask = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n","        pred_mask = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n","\n","        if gt_mask is None or pred_mask is None:\n","            continue\n","\n","        # Resize GT if dimensions don't match (Safety check for unsqueezing issues)\n","        if gt_mask.shape != pred_mask.shape:\n","            gt_mask = cv2.resize(gt_mask, (pred_mask.shape[1], pred_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n","\n","        # Convert to One-Hot\n","        gt_onehot = to_one_hot(gt_mask, NUM_CLASSES)\n","        pred_onehot = to_one_hot(pred_mask, NUM_CLASSES)\n","\n","        # --- Calculate Metrics ---\n","        dice = compute_dice(pred_onehot, gt_onehot, include_background=True)\n","        iou = compute_iou(pred_onehot, gt_onehot, include_background=True)\n","        hd95 = compute_hausdorff_distance(pred_onehot, gt_onehot, include_background=True, percentile=95)\n","\n","        # Store results\n","        file_metrics = {'filename': filename}\n","        for i in range(NUM_CLASSES):\n","            c_name = CLASS_MAP[i]\n","            file_metrics[f\"{c_name}_Dice\"] = dice[0, i].item()\n","            file_metrics[f\"{c_name}_IOU\"] = iou[0, i].item()\n","            file_metrics[f\"{c_name}_HD95\"] = hd95[0, i].item()\n","\n","        results_list.append(file_metrics)\n","\n","    if not results_list:\n","        print(\"No results generated.\")\n","        return\n","\n","    df = pd.DataFrame(results_list)\n","\n","    # Calculate Averages\n","    overall_stats = df.mean(numeric_only=True)\n","\n","    print(\"\\n\\n--- Overall Average Statistics (Test Set) Distance weights ---\")\n","    summary_data = []\n","    for i in range(NUM_CLASSES):\n","        c_name = CLASS_MAP[i]\n","        summary_data.append({\n","            \"Class\": c_name,\n","            \"Dice (↑)\": overall_stats.get(f\"{c_name}_Dice\"),\n","            \"IOU (↑)\": overall_stats.get(f\"{c_name}_IOU\"),\n","            \"HD95 (↓)\": overall_stats.get(f\"{c_name}_HD95\"),\n","        })\n","\n","    summary_df = pd.DataFrame(summary_data)\n","    print(summary_df.to_markdown(index=False, floatfmt=\".4f\"))\n","\n","    # Optional: Save to CSV for comparison later\n","    summary_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/phenocyte_seg/phenocyte_seg/v6_results_summary.csv\", index=False)\n","    print(\"\\nSummary saved to v6_results_summary.csv\")\n","\n","if __name__ == \"__main__\":\n","    run_analysis()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SyJ-b8gXk6ON","executionInfo":{"status":"ok","timestamp":1765377676959,"user_tz":360,"elapsed":9384,"user":{"displayName":"Advait Tilak","userId":"04081556924397245104"}},"outputId":"b815f6b8-5aa8-407c-bbe5-8eb795401912"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting V4 opt Analysis...\n","GT Directory: /content/drive/MyDrive/Colab Notebooks/phenocyte_seg/phenocyte_seg/masks/\n","Pred Directory: /content/drive/MyDrive/Colab Notebooks/phenocyte_seg/phenocyte_seg/outputs_v6_final/pred_masks/test_set/\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.metrics.utils get_mask_edges:always_return_as_numpy: Argument `always_return_as_numpy` has been deprecated since version 1.5.0. It will be removed in version 1.7.0. The option is removed and the return type will always be equal to the input type.\n","  warn_deprecated(argname, msg, warning_category)\n"," 23%|██▎       | 11/47 [00:00<00:02, 12.14it/s]/usr/local/lib/python3.12/dist-packages/monai/metrics/utils.py:327: UserWarning: the ground truth of class 4 is all 0, this may result in nan/inf distance.\n","  warnings.warn(\n"," 87%|████████▋ | 41/47 [00:03<00:00, 11.54it/s]/usr/local/lib/python3.12/dist-packages/monai/metrics/utils.py:332: UserWarning: the prediction of class 4 is all 0, this may result in nan/inf distance.\n","  warnings.warn(\n","100%|██████████| 47/47 [00:04<00:00, 11.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","--- V6 opt Overall Average Statistics (Test Set) Distance weights ---\n","| Class      |   Dice (↑) |   IOU (↑) |   HD95 (↓) |\n","|:-----------|-----------:|----------:|-----------:|\n","| Background |     0.9947 |    0.9895 |     9.4172 |\n","| Stem       |     0.7515 |    0.6148 |     7.0896 |\n","| Leaf       |     0.8489 |    0.7431 |    10.1932 |\n","| Root       |     0.8050 |    0.6865 |    28.8622 |\n","| Seed       |     0.6207 |    0.5206 |     9.2642 |\n","\n","Summary saved to v6_results_summary.csv\n"]}]}]}